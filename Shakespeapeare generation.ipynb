{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SZ3wgn-7Uq18"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JXHuWM48Uq2M"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BEiKP7OJUq2X"
   },
   "outputs": [],
   "source": [
    "path_to_file=\"shakespeare.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NY2QTc7nUq2h"
   },
   "outputs": [],
   "source": [
    "text=open(path_to_file,'r').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9oDXLMD_Uq2r"
   },
   "outputs": [],
   "source": [
    "#print(test[140500:141800])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "duI2aCs-Uq22",
    "outputId": "ceee5819-b4d3-4cc8-96f8-f5d8c63c62e7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5445609"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aWdcntC3Uq3D"
   },
   "outputs": [],
   "source": [
    "vocab=sorted(set(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JDIQ2he8Uq3P",
    "outputId": "88f6e8a4-328f-4e63-e596-f47f941165e1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\n',\n",
       " ' ',\n",
       " '!',\n",
       " '\"',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " ']',\n",
       " '_',\n",
       " '`',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '|',\n",
       " '}']"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "8eBhomtCUq3a",
    "outputId": "968762d9-6447-4943-dc6a-858039394ec6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 9,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jhvkB9aGUq3j",
    "outputId": "bd7e912d-db37-4511-d907-3523597f17ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '\\n')\n",
      "(1, ' ')\n",
      "(2, '!')\n",
      "(3, '\"')\n",
      "(4, '&')\n",
      "(5, \"'\")\n",
      "(6, '(')\n",
      "(7, ')')\n",
      "(8, ',')\n",
      "(9, '-')\n",
      "(10, '.')\n",
      "(11, '0')\n",
      "(12, '1')\n",
      "(13, '2')\n",
      "(14, '3')\n",
      "(15, '4')\n",
      "(16, '5')\n",
      "(17, '6')\n",
      "(18, '7')\n",
      "(19, '8')\n",
      "(20, '9')\n",
      "(21, ':')\n",
      "(22, ';')\n",
      "(23, '<')\n",
      "(24, '>')\n",
      "(25, '?')\n",
      "(26, 'A')\n",
      "(27, 'B')\n",
      "(28, 'C')\n",
      "(29, 'D')\n",
      "(30, 'E')\n",
      "(31, 'F')\n",
      "(32, 'G')\n",
      "(33, 'H')\n",
      "(34, 'I')\n",
      "(35, 'J')\n",
      "(36, 'K')\n",
      "(37, 'L')\n",
      "(38, 'M')\n",
      "(39, 'N')\n",
      "(40, 'O')\n",
      "(41, 'P')\n",
      "(42, 'Q')\n",
      "(43, 'R')\n",
      "(44, 'S')\n",
      "(45, 'T')\n",
      "(46, 'U')\n",
      "(47, 'V')\n",
      "(48, 'W')\n",
      "(49, 'X')\n",
      "(50, 'Y')\n",
      "(51, 'Z')\n",
      "(52, '[')\n",
      "(53, ']')\n",
      "(54, '_')\n",
      "(55, '`')\n",
      "(56, 'a')\n",
      "(57, 'b')\n",
      "(58, 'c')\n",
      "(59, 'd')\n",
      "(60, 'e')\n",
      "(61, 'f')\n",
      "(62, 'g')\n",
      "(63, 'h')\n",
      "(64, 'i')\n",
      "(65, 'j')\n",
      "(66, 'k')\n",
      "(67, 'l')\n",
      "(68, 'm')\n",
      "(69, 'n')\n",
      "(70, 'o')\n",
      "(71, 'p')\n",
      "(72, 'q')\n",
      "(73, 'r')\n",
      "(74, 's')\n",
      "(75, 't')\n",
      "(76, 'u')\n",
      "(77, 'v')\n",
      "(78, 'w')\n",
      "(79, 'x')\n",
      "(80, 'y')\n",
      "(81, 'z')\n",
      "(82, '|')\n",
      "(83, '}')\n"
     ]
    }
   ],
   "source": [
    "for pair in enumerate(vocab):\n",
    "    print(pair)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D2pFPso9Uq3v"
   },
   "outputs": [],
   "source": [
    "char_to_ind={char:ind for ind,char in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "51gI7JBpUq36",
    "outputId": "9737120b-3822-4f0d-8c35-5a561243f427"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 12,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ind['H']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txrnQg3YUq4H"
   },
   "outputs": [],
   "source": [
    "ind_to_char=np.array(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9HSUsWdjUq4P",
    "outputId": "6b43d4f6-6d9c-4486-c906-e7ffd05dc5fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'H'"
      ]
     },
     "execution_count": 14,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5pS69bjjUq4X"
   },
   "outputs": [],
   "source": [
    "encoded_text=np.array([char_to_ind[c] for c in text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "M092dugwUq4f",
    "outputId": "d6748bc5-d976-4fd1-c6f6-a67fcb22d5b6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5445609,)"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1js-rRSEUq4o"
   },
   "outputs": [],
   "source": [
    "sample=text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "id": "WAeVdUduUq4x",
    "outputId": "612d9ae2-6183-4c9e-ed12-3941233bb346"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n                     1\\n  From fairest creatures we desire increase,\\n  That thereby beauty's rose might never die,\\n  But as the riper should by time decease,\\n  His tender heir might bear his memory:\\n  But thou contracted to thine own bright eyes,\\n  Feed'st thy light's flame with self-substantial fuel,\\n  Making a famine where abundance lies,\\n  Thy self thy foe, to thy sweet self too cruel:\\n  Thou that art now the world's fresh ornament,\\n  And only herald to the gaudy spring,\\n  Within thine own bu\""
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 521
    },
    "colab_type": "code",
    "id": "Bu3xSJkKUq47",
    "outputId": "433ef8b7-1671-41e4-c9c1-64c45e6b4ec7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
       "        1,  1,  1,  1,  1, 12,  0,  1,  1, 31, 73, 70, 68,  1, 61, 56, 64,\n",
       "       73, 60, 74, 75,  1, 58, 73, 60, 56, 75, 76, 73, 60, 74,  1, 78, 60,\n",
       "        1, 59, 60, 74, 64, 73, 60,  1, 64, 69, 58, 73, 60, 56, 74, 60,  8,\n",
       "        0,  1,  1, 45, 63, 56, 75,  1, 75, 63, 60, 73, 60, 57, 80,  1, 57,\n",
       "       60, 56, 76, 75, 80,  5, 74,  1, 73, 70, 74, 60,  1, 68, 64, 62, 63,\n",
       "       75,  1, 69, 60, 77, 60, 73,  1, 59, 64, 60,  8,  0,  1,  1, 27, 76,\n",
       "       75,  1, 56, 74,  1, 75, 63, 60,  1, 73, 64, 71, 60, 73,  1, 74, 63,\n",
       "       70, 76, 67, 59,  1, 57, 80,  1, 75, 64, 68, 60,  1, 59, 60, 58, 60,\n",
       "       56, 74, 60,  8,  0,  1,  1, 33, 64, 74,  1, 75, 60, 69, 59, 60, 73,\n",
       "        1, 63, 60, 64, 73,  1, 68, 64, 62, 63, 75,  1, 57, 60, 56, 73,  1,\n",
       "       63, 64, 74,  1, 68, 60, 68, 70, 73, 80, 21,  0,  1,  1, 27, 76, 75,\n",
       "        1, 75, 63, 70, 76,  1, 58, 70, 69, 75, 73, 56, 58, 75, 60, 59,  1,\n",
       "       75, 70,  1, 75, 63, 64, 69, 60,  1, 70, 78, 69,  1, 57, 73, 64, 62,\n",
       "       63, 75,  1, 60, 80, 60, 74,  8,  0,  1,  1, 31, 60, 60, 59,  5, 74,\n",
       "       75,  1, 75, 63, 80,  1, 67, 64, 62, 63, 75,  5, 74,  1, 61, 67, 56,\n",
       "       68, 60,  1, 78, 64, 75, 63,  1, 74, 60, 67, 61,  9, 74, 76, 57, 74,\n",
       "       75, 56, 69, 75, 64, 56, 67,  1, 61, 76, 60, 67,  8,  0,  1,  1, 38,\n",
       "       56, 66, 64, 69, 62,  1, 56,  1, 61, 56, 68, 64, 69, 60,  1, 78, 63,\n",
       "       60, 73, 60,  1, 56, 57, 76, 69, 59, 56, 69, 58, 60,  1, 67, 64, 60,\n",
       "       74,  8,  0,  1,  1, 45, 63, 80,  1, 74, 60, 67, 61,  1, 75, 63, 80,\n",
       "        1, 61, 70, 60,  8,  1, 75, 70,  1, 75, 63, 80,  1, 74, 78, 60, 60,\n",
       "       75,  1, 74, 60, 67, 61,  1, 75, 70, 70,  1, 58, 73, 76, 60, 67, 21,\n",
       "        0,  1,  1, 45, 63, 70, 76,  1, 75, 63, 56, 75,  1, 56, 73, 75,  1,\n",
       "       69, 70, 78,  1, 75, 63, 60,  1, 78, 70, 73, 67, 59,  5, 74,  1, 61,\n",
       "       73, 60, 74, 63,  1, 70, 73, 69, 56, 68, 60, 69, 75,  8,  0,  1,  1,\n",
       "       26, 69, 59,  1, 70, 69, 67, 80,  1, 63, 60, 73, 56, 67, 59,  1, 75,\n",
       "       70,  1, 75, 63, 60,  1, 62, 56, 76, 59, 80,  1, 74, 71, 73, 64, 69,\n",
       "       62,  8,  0,  1,  1, 48, 64, 75, 63, 64, 69,  1, 75, 63, 64, 69, 60,\n",
       "        1, 70, 78, 69,  1, 57, 76])"
      ]
     },
     "execution_count": 19,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text[:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "colab_type": "code",
    "id": "r7Spe9SUUq5F",
    "outputId": "098433bc-66d4-4d6e-cfaf-e7886a3e98ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But as the riper should by time decease,\n",
      "  His tender heir might bear his memory:\n",
      "  But thou contracted to thine own bright eyes,\n",
      "  Feed'st thy light's flame with self-substantial fuel,\n",
      "  Making a famine where abundance lies,\n",
      "  Thy self thy foe, to thy sweet self too cruel:\n",
      "  Thou that art now the world's fresh ornament,\n",
      "  And only herald to the gaudy spring,\n",
      "  Within thine own bu\n"
     ]
    }
   ],
   "source": [
    "print(text[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WVKbXej_Uq5O"
   },
   "outputs": [],
   "source": [
    "line=\"From fairest creatures we desire increase\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "zlR1dpgRUq5V",
    "outputId": "d36b622b-ba80-4ea7-bb12-b1b5251921ac"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lSVh9zNNUq5d"
   },
   "outputs": [],
   "source": [
    "lines='''\n",
    "From fairest creatures we desire increase,\n",
    "  That thereby beauty's rose might never die,\n",
    "  But as the riper should by time decease,\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "xds2HT63Uq5l",
    "outputId": "120fb1c5-354e-400f-91cf-ee244ababa4f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "133"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pseVAIHJUq5t"
   },
   "outputs": [],
   "source": [
    "seq_len = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wuDFiGEpUq51"
   },
   "outputs": [],
   "source": [
    "total_num_seq= len(text)//(seq_len+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "KxWRy3s2Uq6A",
    "outputId": "ae7212b6-84cf-49bb-d395-ef363546fc71"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45005"
      ]
     },
     "execution_count": 27,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_num_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZhIavU1JUq6H"
   },
   "outputs": [],
   "source": [
    "char_dataset=tf.data.Dataset.from_tensor_slices(encoded_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eKr-RBLGUq6P",
    "outputId": "c96254a9-e074-43e8-f0c6-887f004d2ac9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.dataset_ops.TensorSliceDataset"
      ]
     },
     "execution_count": 29,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(char_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X3n1R4uJUq6W"
   },
   "outputs": [],
   "source": [
    "#for item in char_dataset.take(500):\n",
    " #   print(ind_to_char[item.numpy()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w_uKllR6Uq6j"
   },
   "outputs": [],
   "source": [
    "sequences=char_dataset.batch(seq_len+1,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNU1M-ZNUq6w"
   },
   "outputs": [],
   "source": [
    "def create_seq_targets(seq):\n",
    "    input_txt=seq[:-1]\n",
    "    target_txt=seq[1:]\n",
    "    return input_txt,target_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Eobn2gxAUq7C"
   },
   "outputs": [],
   "source": [
    "dataset=sequences.map(create_seq_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 370
    },
    "colab_type": "code",
    "id": "2hzsR7BtUq7L",
    "outputId": "7a6dc664-deff-4a29-bd8a-889f5ae6720f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0\n",
      "  1  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74\n",
      "  1 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45\n",
      " 63 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74\n",
      " 60  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75]\n",
      "\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But\n",
      "\n",
      "\n",
      "[ 1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1 12  0  1\n",
      "  1 31 73 70 68  1 61 56 64 73 60 74 75  1 58 73 60 56 75 76 73 60 74  1\n",
      " 78 60  1 59 60 74 64 73 60  1 64 69 58 73 60 56 74 60  8  0  1  1 45 63\n",
      " 56 75  1 75 63 60 73 60 57 80  1 57 60 56 76 75 80  5 74  1 73 70 74 60\n",
      "  1 68 64 62 63 75  1 69 60 77 60 73  1 59 64 60  8  0  1  1 27 76 75  1]\n",
      "                     1\n",
      "  From fairest creatures we desire increase,\n",
      "  That thereby beauty's rose might never die,\n",
      "  But \n"
     ]
    }
   ],
   "source": [
    "for input_txt,target_txt in dataset.take(1):\n",
    "    print(input_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[input_txt.numpy()]))\n",
    "    print('\\n')\n",
    "    print(target_txt.numpy())\n",
    "    print(\"\".join(ind_to_char[target_txt.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TdFw-AR5Uq7S"
   },
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DHo3xt4tUq7d"
   },
   "outputs": [],
   "source": [
    "buffer_size=10000\n",
    "dataset = dataset.shuffle(buffer_size).batch(batch_size,drop_remainder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "akP5VBJNUq7j",
    "outputId": "36ff6311-7ebf-49c6-e612-231ff28b8ba9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 120), (128, 120)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 37,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TKOSOPM_Uq7q"
   },
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Fli4Hn8iUq7u",
    "outputId": "a7ecbb2b-3a41-4fc0-c9aa-e08c6fd8c910"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 39,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SbllNkxLUq70"
   },
   "outputs": [],
   "source": [
    "embed_dim=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vT8e7Y-LUq74"
   },
   "outputs": [],
   "source": [
    "rnn_neurons=1026"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0SffpJdVUq7-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.losses import sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gbrZpGcbUq8E"
   },
   "outputs": [],
   "source": [
    "def sparse_cat_loss(y_true,y_pred):\n",
    "    return sparse_categorical_crossentropy(y_true,y_pred,\n",
    "                                           from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QxlYoldHUq8J"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding,GRU,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hmARmz2kUq8R"
   },
   "outputs": [],
   "source": [
    "def create_model(vocab_size,embed_dim,rnn_neurons,batch_size):\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocab_size,embed_dim,batch_input_shape=[batch_size,None]))\n",
    "    model.add(GRU(rnn_neurons,return_sequences=True,\n",
    "                  stateful=True,recurrent_initializer='glorot_uniform'))\n",
    "    model.add(Dense(vocab_size))\n",
    "    \n",
    "    model.compile('adam',loss=sparse_cat_loss)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ALjGmhZ2Uq8Z"
   },
   "outputs": [],
   "source": [
    "model= create_model(vocab_size=vocab_size,\n",
    "                   embed_dim=embed_dim,\n",
    "                   rnn_neurons=rnn_neurons,\n",
    "                   batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "vldiHsYIUq8f",
    "outputId": "4dd87387-2783-430e-e03c-dd563b7d417f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (128, None, 64)           5376      \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (128, None, 1026)         3361176   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (128, None, 84)           86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3_TBg0g9Uq8k"
   },
   "outputs": [],
   "source": [
    "for input_example_batch,target_example_batch in dataset.take(1):\n",
    "      example_batch_predictions=model(input_example_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SwnBELtHWS3O"
   },
   "outputs": [],
   "source": [
    "sampled_indices=tf.random.categorical(example_batch_predictions[0],num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QS0NZDTuWYwn"
   },
   "outputs": [],
   "source": [
    "\n",
    "sampled_indices=tf.squeeze(sampled_indices,axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "colab_type": "code",
    "id": "dxaLPYrcXQvh",
    "outputId": "5c9853db-5996-4331-8b32-2032e54439b4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['s', 'i', 'Y', 'X', 'W', 'q', '0', 'U', 'T', 'U', 'U', 'n', 'A',\n",
       "       '?', '&', 't', '|', 'y', 'B', 'l', '>', '3', 'T', 'T', 't', 'F',\n",
       "       'y', 'o', 'x', 'l', '2', 'm', '}', '|', 'G', 't', 'l', 'C', '7',\n",
       "       'w', 'K', '_', 'r', 'Z', 'M', '9', ';', 'g', 'p', 'b', 'n', 'r',\n",
       "       \"'\", 'T', 'A', 'y', 'D', ']', 'r', 'K', 'B', ')', ' ', 'w', '4',\n",
       "       '`', 'S', 'm', 's', 'c', 'c', 'd', 'D', 'm', 'y', '7', 'I', 'R',\n",
       "       '9', 'f', 'p', 'c', 'j', '_', 'T', 'w', '1', '|', '9', 'a', 'a',\n",
       "       'g', 'd', 'f', '0', 'O', 'H', 'q', '7', 'B', 'S', 'K', '\\n', ':',\n",
       "       's', 'u', 'j', ':', '!', 'e', 'y', '<', '_', '.', 'X', 't', '>',\n",
       "       'z', 'z', 'Q'], dtype='<U1')"
      ]
     },
     "execution_count": 55,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ind_to_char[sampled_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LERlCGZZXkMU"
   },
   "outputs": [],
   "source": [
    "epochs=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "CrYu3UWSX3B-",
    "outputId": "a683b7d3-a306-4b59-f053-b7e4d7089f24"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 2.5226\n",
      "Epoch 2/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.7113\n",
      "Epoch 3/30\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 1.4468\n",
      "Epoch 4/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.3329\n",
      "Epoch 5/30\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 1.2723\n",
      "Epoch 6/30\n",
      "351/351 [==============================] - 31s 90ms/step - loss: 1.2326\n",
      "Epoch 7/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.2025\n",
      "Epoch 8/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.1789\n",
      "Epoch 9/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.1592\n",
      "Epoch 10/30\n",
      "351/351 [==============================] - 31s 90ms/step - loss: 1.1423\n",
      "Epoch 11/30\n",
      "351/351 [==============================] - 31s 90ms/step - loss: 1.1267\n",
      "Epoch 12/30\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 1.1124\n",
      "Epoch 13/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.0993\n",
      "Epoch 14/30\n",
      "351/351 [==============================] - 32s 91ms/step - loss: 1.0865\n",
      "Epoch 15/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.0751\n",
      "Epoch 16/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.0637\n",
      "Epoch 17/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.0529\n",
      "Epoch 18/30\n",
      "351/351 [==============================] - 32s 91ms/step - loss: 1.0429\n",
      "Epoch 19/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.0340\n",
      "Epoch 20/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.0249\n",
      "Epoch 21/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 1.0170\n",
      "Epoch 22/30\n",
      "351/351 [==============================] - 31s 89ms/step - loss: 1.0097\n",
      "Epoch 23/30\n",
      "351/351 [==============================] - 32s 91ms/step - loss: 1.0031\n",
      "Epoch 24/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.9965\n",
      "Epoch 25/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.9912\n",
      "Epoch 26/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.9860\n",
      "Epoch 27/30\n",
      "351/351 [==============================] - 31s 90ms/step - loss: 0.9813\n",
      "Epoch 28/30\n",
      "351/351 [==============================] - 31s 90ms/step - loss: 0.9776\n",
      "Epoch 29/30\n",
      "351/351 [==============================] - 31s 90ms/step - loss: 0.9735\n",
      "Epoch 30/30\n",
      "351/351 [==============================] - 32s 90ms/step - loss: 0.9709\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f5a95a74358>"
      ]
     },
     "execution_count": 57,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(dataset,epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LVAzLgUSX_Zw"
   },
   "outputs": [],
   "source": [
    "model.save('shakespeare_gen1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sbnU8kuJdEtO"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vK3I-mb3dp_g"
   },
   "outputs": [],
   "source": [
    "model=create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)\n",
    "\n",
    "model.load_weights('shakespeare_gen.h5')\n",
    "\n",
    "model.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 252
    },
    "colab_type": "code",
    "id": "bbTbQgL5ec3R",
    "outputId": "e2acb6e8-9453-4543-8242-e0e3537ba18a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (1, None, 64)             5376      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (1, None, 1026)           3361176   \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (1, None, 84)             86268     \n",
      "=================================================================\n",
      "Total params: 3,452,820\n",
      "Trainable params: 3,452,820\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o3BS5NKKehcS"
   },
   "outputs": [],
   "source": [
    "def generate_text(model,start_seed,gen_size=500,temp=1.0):\n",
    "     num_generate= gen_size\n",
    "\n",
    "     input_eval = [char_to_ind[s] for s in start_seed]\n",
    "\n",
    "     input_eval = tf.expand_dims(input_eval,0)\n",
    "\n",
    "     text_generated = []\n",
    "\n",
    "     temperature = temp\n",
    "\n",
    "     model.reset_states()\n",
    "\n",
    "     for i in range(num_generate):\n",
    "         predictions = model(input_eval)\n",
    "\n",
    "         predictions = tf.squeeze(predictions,0)\n",
    "\n",
    "         predictions = predictions/temperature\n",
    "\n",
    "         predicted_id = tf.random.categorical(predictions,num_samples=1)[-1,0].numpy()\n",
    "        \n",
    "         input_eval = tf.expand_dims([predicted_id],0)\n",
    "\n",
    "         text_generated.append(ind_to_char[predicted_id])\n",
    "\n",
    "     return (start_seed+\"\".join(text_generated))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 457
    },
    "colab_type": "code",
    "id": "fHfnNy2OjZnk",
    "outputId": "d166e981-f2c0-4ec4-f755-ee4e267054df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIETT'S battle\n",
      "    Pierc'd to your fortune fall! A light than me!\n",
      "    Nor furnish Forder and [Exit, as to the laborous Dannence, Thou hast lov'd us, Moors but there. When I sport.\n",
      "  DLOON. Jut not along,\n",
      "    And no more merits with my brain and silver.\n",
      "  DUKE. What hast done?\n",
      "  SERVANT. Stay, what, for you are most liv'd?\n",
      "  AGUECHEEK. Put them achors; to-morrow! Master Ford, my lord.\n",
      "  KING RICHARD. Let us to my knees, I would bring you there.\n",
      "  KING JOHN. From body for  Vilentive heavens!  \n",
      "  FEEBLOTHBOOD CITIZEB. Gentlemen of Charmia-\n",
      "  CASSIUS. Frivant, by his liberty.\n",
      "  ELBOW. Marry, prepare; or if not a couple om\n",
      "    your chamber, abode me forneath'd by,\n",
      "    I question to your sport, and let us look,\n",
      "    As they have their affections are mock'd!\n",
      "  PLAget?\n",
      "  AGUECHEEK. 'Go, faith, we at all the last.\n",
      "\n",
      "  RODERIGO. Not a word; but that so long\n",
      "    Must know at a creep into a cog\n",
      "    To kiss her; and oftener.\n",
      "  PAULINA. This is such late.\n",
      "  PANTHINO. 'Tis a mile\n",
      "    Than I intend to girdl\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model,\"JULIET\",gen_size=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e2mDAbkxjrtU"
   },
   "outputs": [],
   "source": [
    "model1=create_model(vocab_size,embed_dim,rnn_neurons,batch_size=1)\n",
    "\n",
    "model1.load_weights('shakespeare_gen1.h5')\n",
    "\n",
    "model1.build(tf.TensorShape([1,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "colab_type": "code",
    "id": "ShvmP_Plkd2b",
    "outputId": "48677a00-dc01-4f5c-e04b-ac91224fec2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JULIETEXTUCT [SHADY. Will't plue-\n",
      "  GREEN. I follow, I am possess'd with his sword.              Exit  \n",
      "  PATROCLUS. Will it be.  \n",
      "  Hot. Nature, dids?\n",
      "  GLOUCESTER. Ay, that he is not- - Julia made me and unfold within.\n",
      "  OLIVER. Come hither, sirrah.       And make thee freely; Bolingbroke's, insinuatican'd and lovely\n",
      "    better day my put the sea survive to herself, for here which note\n",
      "    tent to Laro shed,\n",
      "   ATES. That which by your daughter sayish Deorey. The sweetest guiser, mocking therein- a stone\n",
      "    indeed.\n",
      "  MALVOLIO. A drugral, thou largers constantinaty\n",
      "    For cold more than he was for sword. Like anm\n",
      "    good, i' th' rich, or else do you know of them? You do remembate, no\n",
      "    notable sinour choice?\n",
      "  APEMANTUS. We have mark'n Saturnine, it done, go to;  \n",
      "    Have stretch'd to on. Let me embrace too, I like no other.\n",
      "    Which liking to this demunessate, distracted,\n",
      "  Of what has her wrengning by drinkill dares you think,\n",
      "    If this be into tons, que life to you.\n",
      "  AARON. But\n"
     ]
    }
   ],
   "source": [
    "print(generate_text(model1,\"JULIET\",gen_size=1000))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
